{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a31fce7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T13:21:29.107550Z",
     "start_time": "2022-05-21T13:21:29.098085Z"
    }
   },
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dbc8f1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T11:25:14.309814Z",
     "start_time": "2022-05-22T11:25:11.204569Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import Lambda\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import F1Score, ConfusionMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2705a7",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0fdf303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T11:25:14.369010Z",
     "start_time": "2022-05-22T11:25:14.309814Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(\"../datasets/\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(\"../datasets/\", train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075cc304",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b17f5ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T11:25:14.389310Z",
     "start_time": "2022-05-22T11:25:14.370031Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77239a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T12:39:49.891581Z",
     "start_time": "2022-05-21T12:39:49.866732Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1fb2a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T12:28:38.981717Z",
     "start_time": "2022-05-21T12:28:38.963817Z"
    }
   },
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8edc5f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T11:25:14.429315Z",
     "start_time": "2022-05-22T11:25:14.389831Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=64, bias=True)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (output): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_feature):\n",
    "        super(Model, self).__init__()\n",
    "                \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(n_feature, 64),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(64, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.output = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_fc1 = self.fc1(x)\n",
    "        x_fc2 = self.fc2(x_fc1)\n",
    "        output = self.output(x_fc2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "model = Model(n_feature=28 * 28)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6778f1ed",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "158b944c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T11:25:14.449411Z",
     "start_time": "2022-05-22T11:25:14.429835Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLLLoss()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_metric = nn.NLLLoss()\n",
    "loss_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7308ee",
   "metadata": {},
   "source": [
    "## Eval Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "018682ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T11:25:14.469033Z",
     "start_time": "2022-05-22T11:25:14.449941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F1Score()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metric = F1Score(num_classes=10)\n",
    "eval_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c90028",
   "metadata": {},
   "source": [
    "## Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "924f59b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T11:25:14.489293Z",
     "start_time": "2022-05-22T11:25:14.470055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f6572d",
   "metadata": {},
   "source": [
    "## Loop Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dee82ac9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T11:25:14.508982Z",
     "start_time": "2022-05-22T11:25:14.489809Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'05-22-2022_19-25-14'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "now = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b64c116",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-22T11:25:11.491Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/5\n",
      "==============================================\n",
      "Train\n",
      "\n",
      "Batch-100  | F1-Score: 0.625000 | Loss: -0.549520\n",
      "Batch-200  | F1-Score: 0.625000 | Loss: -0.554258\n",
      "Batch-300  | F1-Score: 0.781250 | Loss: -0.775061\n",
      "Batch-400  | F1-Score: 0.937500 | Loss: -0.854262\n",
      "Batch-500  | F1-Score: 0.750000 | Loss: -0.730091\n",
      "Batch-600  | F1-Score: 0.812500 | Loss: -0.774481\n",
      "Batch-700  | F1-Score: 0.906250 | Loss: -0.890847\n",
      "Batch-800  | F1-Score: 0.843750 | Loss: -0.833138\n",
      "Batch-900  | F1-Score: 0.843750 | Loss: -0.805579\n",
      "Batch-1000 | F1-Score: 0.812500 | Loss: -0.810132\n",
      "Batch-1100 | F1-Score: 0.843750 | Loss: -0.818337\n",
      "Batch-1200 | F1-Score: 0.875000 | Loss: -0.864546\n",
      "Batch-1300 | F1-Score: 0.843750 | Loss: -0.842700\n",
      "Batch-1400 | F1-Score: 0.750000 | Loss: -0.748103\n",
      "Batch-1500 | F1-Score: 0.781250 | Loss: -0.755098\n",
      "Batch-1600 | F1-Score: 0.843750 | Loss: -0.832624\n",
      "Batch-1700 | F1-Score: 0.906250 | Loss: -0.876009\n",
      "Batch-1800 | F1-Score: 0.906250 | Loss: -0.905216\n",
      "Accuracy : 0.7971166372299194\n",
      "Loss     : -0.7697447831908861\n",
      "\n",
      "Test\n",
      "\n",
      "Batch-100  | F1-Score: 0.875000 | Loss: -0.873187\n",
      "Batch-200  | F1-Score: 0.875000 | Loss: -0.862676\n",
      "Batch-300  | F1-Score: 0.968750 | Loss: -0.948121\n",
      "Accuracy : 0.8341000080108643\n",
      "Loss     : -0.826101471821721\n",
      "==============================================\n",
      "\n",
      "EPOCH 2/5\n",
      "==============================================\n",
      "Train\n",
      "\n",
      "Batch-100  | F1-Score: 0.843750 | Loss: -0.823170\n",
      "Batch-200  | F1-Score: 0.875000 | Loss: -0.875340\n",
      "Batch-300  | F1-Score: 0.937500 | Loss: -0.922664\n",
      "Batch-400  | F1-Score: 0.812500 | Loss: -0.807581\n",
      "Batch-500  | F1-Score: 0.875000 | Loss: -0.870605\n",
      "Batch-600  | F1-Score: 0.812500 | Loss: -0.812817\n",
      "Batch-700  | F1-Score: 0.750000 | Loss: -0.747883\n",
      "Batch-800  | F1-Score: 0.875000 | Loss: -0.881151\n",
      "Batch-900  | F1-Score: 0.937500 | Loss: -0.913134\n",
      "Batch-1000 | F1-Score: 0.812500 | Loss: -0.826996\n",
      "Batch-1100 | F1-Score: 0.906250 | Loss: -0.897530\n",
      "Batch-1200 | F1-Score: 0.687500 | Loss: -0.679178\n",
      "Batch-1300 | F1-Score: 0.906250 | Loss: -0.895250\n",
      "Batch-1400 | F1-Score: 0.875000 | Loss: -0.845539\n",
      "Batch-1500 | F1-Score: 0.906250 | Loss: -0.873546\n",
      "Batch-1600 | F1-Score: 0.906250 | Loss: -0.906411\n",
      "Batch-1700 | F1-Score: 0.906250 | Loss: -0.876982\n",
      "Batch-1800 | F1-Score: 0.812500 | Loss: -0.798429\n",
      "Accuracy : 0.8418166637420654\n",
      "Loss     : -0.8341871700604757\n",
      "\n",
      "Test\n",
      "\n",
      "Batch-100  | F1-Score: 0.843750 | Loss: -0.821249\n"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_metric, eval_metric, optimizer):\n",
    "    print(\"Train\\n\")\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for batch, (feature, actual_label) in enumerate(dataloader, 1):\n",
    "        # Forward Propagation\n",
    "        pred_label = model(feature)\n",
    "        loss = loss_metric(pred_label, actual_label)\n",
    "        evaluate_metric = eval_metric(pred_label, actual_label)\n",
    "        \n",
    "        # Backward Propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss = loss.item()\n",
    "        losses.append(loss)\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Batch-{batch:<4} | F1-Score: {evaluate_metric:>7f} | Loss: {loss:>7f}\")\n",
    "    \n",
    "    evaluate_metric = eval_metric.compute()\n",
    "    loss = sum(losses) / len(dataloader)\n",
    "    print(f\"Accuracy : {evaluate_metric}\")\n",
    "    print(f\"Loss     : {loss}\\n\")\n",
    "    eval_metric.reset()\n",
    "    \n",
    "    return evaluate_metric, loss\n",
    "\n",
    "def validate(dataloader, model, loss_metric, eval_metric):\n",
    "    print(\"Test\\n\")\n",
    "    \n",
    "    model.train()\n",
    "    losses = []\n",
    "    \n",
    "    for batch, (feature, actual_label) in enumerate(dataloader, 1):\n",
    "        # Forward Propagation\n",
    "        pred_label = model(feature)\n",
    "        loss = loss_metric(pred_label, actual_label)\n",
    "        evaluate_metric = eval_metric(pred_label, actual_label)\n",
    "        \n",
    "        \n",
    "        loss = loss.item()\n",
    "        losses.append(loss)\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Batch-{batch:<4} | F1-Score: {evaluate_metric:>7f} | Loss: {loss:>7f}\")\n",
    "    \n",
    "    evaluate_metric = eval_metric.compute()\n",
    "    loss = sum(losses) / len(dataloader)\n",
    "    print(f\"Accuracy : {evaluate_metric}\")\n",
    "    print(f\"Loss     : {loss}\")\n",
    "    eval_metric.reset()\n",
    "    \n",
    "    return evaluate_metric, loss\n",
    "\n",
    "def loop(train, validate, epochs=5):\n",
    "    now = datetime.now()\n",
    "    now = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "    os.makedirs(\"../pretrained_model/\" + str(now) + \"/model\")\n",
    "    \n",
    "    train_accuracies, train_losses = [], []\n",
    "    test_accuracies, test_losses = [], []\n",
    "\n",
    "    start = time()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"EPOCH {epoch + 1}/{epochs}\")\n",
    "        print(\"=\" * 46, end=\"\\n\")\n",
    "        acc_train, loss_train = train(train_loader, model, loss_metric, eval_metric, optimizer)\n",
    "        acc_test, loss_test = validate(test_loader, model, loss_metric, eval_metric)\n",
    "\n",
    "        print(\"=\" * 46, end=\"\\n\\n\")\n",
    "        \n",
    "        train_accuracies.append(acc_train)\n",
    "        train_losses.append(loss_train)\n",
    "        test_accuracies.append(acc_test)\n",
    "        test_losses.append(loss_test)\n",
    "        \n",
    "        torch.save(model.state_dict(), \"../pretrained_model/\" + now + \"/model/epoch_\" + str(epoch + 1) + \".pt\")\n",
    "\n",
    "    print(\"SUMMARY:\")\n",
    "    print(f\"Train Accuracy : {sum(train_accuracies) / len(train_accuracies)}\")\n",
    "    print(f\"Train Loss     : {sum(train_losses) / len(train_losses)}\\n\")\n",
    "    print(f\"Test Accuracy  : {sum(test_accuracies) / len(test_accuracies)}\")\n",
    "    print(f\"Test Loss      : {sum(test_losses) / len(test_losses)}\")\n",
    "\n",
    "    stop = time()\n",
    "\n",
    "    total_time = stop - start\n",
    "    print(f\"Training time: {(total_time / 60):.3f} minutes\")\n",
    "    \n",
    "    return {\"train_accuracies\": train_accuracies, \"train_losses\": train_losses, \"test_accuracies\": test_accuracies, \"test_losses\": test_losses}\n",
    "\n",
    "summary = loop(train, validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "633dc709",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-22T11:25:11.545Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, tight_layout=True, figsize=(12, 8))\n",
    "\n",
    "ax[0][0].set_title(\"Train\")\n",
    "ax[0][0].plot(summary[\"train_accuracies\"], label=\"accuracy\")\n",
    "ax[0][0].plot(summary[\"train_losses\"], label=\"loss\")\n",
    "ax[0][0].set_xlabel(\"Epoch\")\n",
    "ax[0][0].set_ylabel(\"Score\")\n",
    "ax[0][0].legend()\n",
    "ax[0][0].grid();\n",
    "\n",
    "ax[0][1].set_title(\"Test\")\n",
    "ax[0][1].plot(summary[\"test_accuracies\"], label=\"accuracy\")\n",
    "ax[0][1].plot(summary[\"test_losses\"], label=\"loss\")\n",
    "ax[0][1].set_xlabel(\"Epoch\")\n",
    "ax[0][1].set_ylabel(\"Score\")\n",
    "ax[0][1].legend()\n",
    "ax[0][1].grid();\n",
    "\n",
    "ax[1][0].set_title(\"Train Accuracy and Test Accuracy\")\n",
    "ax[1][0].plot(summary[\"train_accuracies\"], label=\"accuracy train\")\n",
    "ax[1][0].plot(summary[\"test_accuracies\"], label=\"accuracy test\")\n",
    "ax[1][0].set_xlabel(\"Epoch\")\n",
    "ax[1][0].set_ylabel(\"Score\")\n",
    "ax[1][0].legend()\n",
    "ax[1][0].grid();\n",
    "\n",
    "ax[1][1].set_title(\"Train Loss and Test Loss\")\n",
    "ax[1][1].plot(summary[\"train_losses\"], label=\"loss train\")\n",
    "ax[1][1].plot(summary[\"test_losses\"], label=\"loss test\")\n",
    "ax[1][1].set_xlabel(\"Epoch\")\n",
    "ax[1][1].set_ylabel(\"Score\")\n",
    "ax[1][1].legend()\n",
    "ax[1][1].grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30203997",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8b1a5b",
   "metadata": {},
   "source": [
    "## Predict with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf45c74d",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-22T11:25:11.589Z"
    }
   },
   "outputs": [],
   "source": [
    "features, labels = next(iter(test_loader))\n",
    "\n",
    "model.eval()\n",
    "pred_labels = model(features).argmax(dim=1)\n",
    "\n",
    "fig, axes = plt.subplots(8, 4, figsize=(24, 24))\n",
    "\n",
    "for image, label, pred_label, ax in zip(features, labels, pred_labels, axes.flatten()):\n",
    "    ax.imshow(image.permute(1, 2, 0).cpu(), cmap=plt.cm.gray)\n",
    "    font = {\"color\": \"red\"} if label != pred_label else {\"color\": \"green\"}\n",
    "    ax.set_title(f\"Label: {label} | Pred: {pred_label}\", fontdict=font)\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea05323",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181e0807",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-22T11:25:11.625Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model, dataloader):\n",
    "    actual_labels = dataloader.dataset.targets\n",
    "    features = dataloader.dataset.data.to(dtype=torch.float32)\n",
    "    \n",
    "    model.eval()\n",
    "    pred_labels = model(features).argmax(dim=1)\n",
    "    confusion_matrix = ConfusionMatrix(num_classes=10)\n",
    "    \n",
    "    ax = sns.heatmap(confusion_matrix(pred_labels, actual_labels), annot=True, fmt=\"d\")\n",
    "    ax.set(\n",
    "        xlabel=\"Prediction\",\n",
    "        ylabel=\"Actual\"\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c12674b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-22T11:25:11.653Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5676d26",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-05-22T11:25:11.674Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b997a578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep_learning] *",
   "language": "python",
   "name": "conda-env-deep_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "252.533px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
