{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a31fce7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T13:21:29.107550Z",
     "start_time": "2022-05-21T13:21:29.098085Z"
    }
   },
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dbc8f1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T13:14:42.020805Z",
     "start_time": "2022-05-22T13:14:31.992323Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "from datetime import datetime\n",
    "from time import time\n",
    "from torch import nn, optim\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import Lambda\n",
    "from torch.utils.data import DataLoader\n",
    "from torchmetrics import F1Score, ConfusionMatrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2705a7",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0fdf303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T13:14:42.211899Z",
     "start_time": "2022-05-22T13:14:42.033175Z"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(\"../datasets/\", train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(\"../datasets/\", train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075cc304",
   "metadata": {},
   "source": [
    "# Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b17f5ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T13:14:42.243407Z",
     "start_time": "2022-05-22T13:14:42.223897Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77239a4f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T12:39:49.891581Z",
     "start_time": "2022-05-21T12:39:49.866732Z"
    },
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b1fb2a3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-21T12:28:38.981717Z",
     "start_time": "2022-05-21T12:28:38.963817Z"
    }
   },
   "source": [
    "## Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8edc5f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T13:14:42.329644Z",
     "start_time": "2022-05-22T13:14:42.264583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Model(\n",
       "  (fc1): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=784, out_features=64, bias=True)\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): ReLU()\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=64, out_features=10, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (output): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, n_feature):\n",
    "        super(Model, self).__init__()\n",
    "                \n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(n_feature, 64),\n",
    "            nn.Dropout(p=0.1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(64, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "        self.output = nn.Softmax(dim=1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_fc1 = self.fc1(x)\n",
    "        x_fc2 = self.fc2(x_fc1)\n",
    "        output = self.output(x_fc2)\n",
    "        \n",
    "        return output\n",
    "\n",
    "model = Model(n_feature=28 * 28)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6778f1ed",
   "metadata": {},
   "source": [
    "## Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "158b944c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T13:14:42.354740Z",
     "start_time": "2022-05-22T13:14:42.337569Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NLLLoss()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_metric = nn.NLLLoss()\n",
    "loss_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a7308ee",
   "metadata": {},
   "source": [
    "## Eval Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "018682ea",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T13:14:42.384992Z",
     "start_time": "2022-05-22T13:14:42.360742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "F1Score()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_metric = F1Score(num_classes=10)\n",
    "eval_metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c90028",
   "metadata": {},
   "source": [
    "## Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "924f59b3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T13:14:42.416039Z",
     "start_time": "2022-05-22T13:14:42.389983Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Adam (\n",
       "Parameter Group 0\n",
       "    amsgrad: False\n",
       "    betas: (0.9, 0.999)\n",
       "    eps: 1e-08\n",
       "    lr: 0.001\n",
       "    maximize: False\n",
       "    weight_decay: 0\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer = optim.Adam(model.parameters())\n",
    "optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f6572d",
   "metadata": {},
   "source": [
    "## Loop Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b64c116",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T13:18:51.760144Z",
     "start_time": "2022-05-22T13:14:42.422168Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1/5\n",
      "==============================================\n",
      "Train\n",
      "\n",
      "Batch-100  | F1-Score: 0.687500 | Loss: -0.541978\n",
      "Batch-200  | F1-Score: 0.781250 | Loss: -0.739663\n",
      "Batch-300  | F1-Score: 0.656250 | Loss: -0.602280\n",
      "Batch-400  | F1-Score: 0.531250 | Loss: -0.489864\n",
      "Batch-500  | F1-Score: 0.718750 | Loss: -0.708607\n",
      "Batch-600  | F1-Score: 0.875000 | Loss: -0.840415\n",
      "Batch-700  | F1-Score: 0.812500 | Loss: -0.780484\n",
      "Batch-800  | F1-Score: 0.656250 | Loss: -0.655790\n",
      "Batch-900  | F1-Score: 0.718750 | Loss: -0.709306\n",
      "Batch-1000 | F1-Score: 0.781250 | Loss: -0.758891\n",
      "Batch-1100 | F1-Score: 0.781250 | Loss: -0.772574\n",
      "Batch-1200 | F1-Score: 0.687500 | Loss: -0.681055\n",
      "Batch-1300 | F1-Score: 0.812500 | Loss: -0.821011\n",
      "Batch-1400 | F1-Score: 0.781250 | Loss: -0.756388\n",
      "Batch-1500 | F1-Score: 0.750000 | Loss: -0.726985\n",
      "Batch-1600 | F1-Score: 0.718750 | Loss: -0.726967\n",
      "Batch-1700 | F1-Score: 0.812500 | Loss: -0.806414\n",
      "Batch-1800 | F1-Score: 0.750000 | Loss: -0.739290\n",
      "Accuracy : 0.7201666831970215\n",
      "Loss     : -0.6936327812472979\n",
      "\n",
      "Test\n",
      "\n",
      "Batch-100  | F1-Score: 0.625000 | Loss: -0.625617\n",
      "Batch-200  | F1-Score: 0.781250 | Loss: -0.772383\n",
      "Batch-300  | F1-Score: 0.843750 | Loss: -0.841501\n",
      "Accuracy : 0.7544999718666077\n",
      "Loss     : -0.7463700824652236\n",
      "==============================================\n",
      "\n",
      "EPOCH 2/5\n",
      "==============================================\n",
      "Train\n",
      "\n",
      "Batch-100  | F1-Score: 0.781250 | Loss: -0.769589\n",
      "Batch-200  | F1-Score: 0.718750 | Loss: -0.700950\n",
      "Batch-300  | F1-Score: 0.781250 | Loss: -0.784764\n",
      "Batch-400  | F1-Score: 0.781250 | Loss: -0.783440\n",
      "Batch-500  | F1-Score: 0.843750 | Loss: -0.844102\n",
      "Batch-600  | F1-Score: 0.656250 | Loss: -0.663308\n",
      "Batch-700  | F1-Score: 0.875000 | Loss: -0.875766\n",
      "Batch-800  | F1-Score: 0.718750 | Loss: -0.730185\n",
      "Batch-900  | F1-Score: 0.781250 | Loss: -0.787309\n",
      "Batch-1000 | F1-Score: 0.750000 | Loss: -0.753147\n",
      "Batch-1100 | F1-Score: 0.781250 | Loss: -0.782263\n",
      "Batch-1200 | F1-Score: 0.781250 | Loss: -0.794425\n",
      "Batch-1300 | F1-Score: 0.781250 | Loss: -0.756160\n",
      "Batch-1400 | F1-Score: 0.625000 | Loss: -0.619770\n",
      "Batch-1500 | F1-Score: 0.750000 | Loss: -0.757437\n",
      "Batch-1600 | F1-Score: 0.812500 | Loss: -0.825943\n",
      "Batch-1700 | F1-Score: 0.781250 | Loss: -0.796005\n",
      "Batch-1800 | F1-Score: 0.718750 | Loss: -0.702330\n",
      "Accuracy : 0.7535333037376404\n",
      "Loss     : -0.7512937762260437\n",
      "\n",
      "Test\n",
      "\n",
      "Batch-100  | F1-Score: 0.718750 | Loss: -0.725710\n",
      "Batch-200  | F1-Score: 0.750000 | Loss: -0.740281\n",
      "Batch-300  | F1-Score: 0.875000 | Loss: -0.848366\n",
      "Accuracy : 0.7631000280380249\n",
      "Loss     : -0.7637548696118802\n",
      "==============================================\n",
      "\n",
      "EPOCH 3/5\n",
      "==============================================\n",
      "Train\n",
      "\n",
      "Batch-100  | F1-Score: 0.843750 | Loss: -0.835911\n",
      "Batch-200  | F1-Score: 0.750000 | Loss: -0.748464\n",
      "Batch-300  | F1-Score: 0.750000 | Loss: -0.758906\n",
      "Batch-400  | F1-Score: 0.843750 | Loss: -0.851031\n",
      "Batch-500  | F1-Score: 0.750000 | Loss: -0.751476\n",
      "Batch-600  | F1-Score: 0.812500 | Loss: -0.831822\n",
      "Batch-700  | F1-Score: 0.750000 | Loss: -0.758491\n",
      "Batch-800  | F1-Score: 0.531250 | Loss: -0.548693\n",
      "Batch-900  | F1-Score: 0.593750 | Loss: -0.605163\n",
      "Batch-1000 | F1-Score: 0.812500 | Loss: -0.821269\n",
      "Batch-1100 | F1-Score: 0.718750 | Loss: -0.724352\n",
      "Batch-1200 | F1-Score: 0.750000 | Loss: -0.765756\n",
      "Batch-1300 | F1-Score: 0.812500 | Loss: -0.794766\n",
      "Batch-1400 | F1-Score: 0.906250 | Loss: -0.911729\n",
      "Batch-1500 | F1-Score: 0.750000 | Loss: -0.743610\n",
      "Batch-1600 | F1-Score: 0.812500 | Loss: -0.826511\n",
      "Batch-1700 | F1-Score: 0.750000 | Loss: -0.766911\n",
      "Batch-1800 | F1-Score: 0.718750 | Loss: -0.730503\n",
      "Accuracy : 0.7628166675567627\n",
      "Loss     : -0.7662643862088522\n",
      "\n",
      "Test\n",
      "\n",
      "Batch-100  | F1-Score: 0.750000 | Loss: -0.758528\n",
      "Batch-200  | F1-Score: 0.687500 | Loss: -0.698689\n",
      "Batch-300  | F1-Score: 0.781250 | Loss: -0.789303\n",
      "Accuracy : 0.7682999968528748\n",
      "Loss     : -0.7746424534069464\n",
      "==============================================\n",
      "\n",
      "EPOCH 4/5\n",
      "==============================================\n",
      "Train\n",
      "\n",
      "Batch-100  | F1-Score: 0.750000 | Loss: -0.769767\n",
      "Batch-200  | F1-Score: 0.781250 | Loss: -0.793552\n",
      "Batch-300  | F1-Score: 0.718750 | Loss: -0.702368\n",
      "Batch-400  | F1-Score: 0.500000 | Loss: -0.528271\n",
      "Batch-500  | F1-Score: 0.687500 | Loss: -0.704770\n",
      "Batch-600  | F1-Score: 0.781250 | Loss: -0.774342\n",
      "Batch-700  | F1-Score: 0.718750 | Loss: -0.721351\n",
      "Batch-800  | F1-Score: 0.562500 | Loss: -0.586539\n",
      "Batch-900  | F1-Score: 0.781250 | Loss: -0.797332\n",
      "Batch-1000 | F1-Score: 0.750000 | Loss: -0.777118\n",
      "Batch-1100 | F1-Score: 0.812500 | Loss: -0.819506\n",
      "Batch-1200 | F1-Score: 0.812500 | Loss: -0.813508\n",
      "Batch-1300 | F1-Score: 0.875000 | Loss: -0.879126\n",
      "Batch-1400 | F1-Score: 0.875000 | Loss: -0.858690\n",
      "Batch-1500 | F1-Score: 0.781250 | Loss: -0.796029\n",
      "Batch-1600 | F1-Score: 0.812500 | Loss: -0.817838\n",
      "Batch-1700 | F1-Score: 0.843750 | Loss: -0.850242\n",
      "Batch-1800 | F1-Score: 0.843750 | Loss: -0.859763\n",
      "Accuracy : 0.7967666387557983\n",
      "Loss     : -0.8019391124725341\n",
      "\n",
      "Test\n",
      "\n",
      "Batch-100  | F1-Score: 0.906250 | Loss: -0.908680\n",
      "Batch-200  | F1-Score: 0.906250 | Loss: -0.874699\n",
      "Batch-300  | F1-Score: 0.968750 | Loss: -0.950665\n",
      "Accuracy : 0.8537999987602234\n",
      "Loss     : -0.8557149699320808\n",
      "==============================================\n",
      "\n",
      "EPOCH 5/5\n",
      "==============================================\n",
      "Train\n",
      "\n",
      "Batch-100  | F1-Score: 0.781250 | Loss: -0.785832\n",
      "Batch-200  | F1-Score: 0.843750 | Loss: -0.844647\n",
      "Batch-300  | F1-Score: 0.781250 | Loss: -0.786526\n",
      "Batch-400  | F1-Score: 0.843750 | Loss: -0.863638\n",
      "Batch-500  | F1-Score: 0.937500 | Loss: -0.928772\n",
      "Batch-600  | F1-Score: 0.843750 | Loss: -0.842599\n",
      "Batch-700  | F1-Score: 0.812500 | Loss: -0.818347\n",
      "Batch-800  | F1-Score: 0.937500 | Loss: -0.936490\n",
      "Batch-900  | F1-Score: 0.812500 | Loss: -0.807212\n",
      "Batch-1000 | F1-Score: 0.781250 | Loss: -0.787257\n",
      "Batch-1100 | F1-Score: 0.843750 | Loss: -0.849082\n",
      "Batch-1200 | F1-Score: 0.875000 | Loss: -0.847848\n",
      "Batch-1300 | F1-Score: 0.875000 | Loss: -0.883797\n",
      "Batch-1400 | F1-Score: 0.906250 | Loss: -0.885889\n",
      "Batch-1500 | F1-Score: 0.875000 | Loss: -0.880423\n",
      "Batch-1600 | F1-Score: 0.843750 | Loss: -0.855661\n",
      "Batch-1700 | F1-Score: 0.843750 | Loss: -0.857817\n",
      "Batch-1800 | F1-Score: 0.875000 | Loss: -0.877336\n",
      "Accuracy : 0.8592666983604431\n",
      "Loss     : -0.861540603129069\n",
      "\n",
      "Test\n",
      "\n",
      "Batch-100  | F1-Score: 0.750000 | Loss: -0.750459\n",
      "Batch-200  | F1-Score: 0.875000 | Loss: -0.883787\n",
      "Batch-300  | F1-Score: 0.812500 | Loss: -0.819813\n",
      "Accuracy : 0.8634999990463257\n",
      "Loss     : -0.8671174032238725\n",
      "==============================================\n",
      "\n",
      "SUMMARY:\n",
      "Train Accuracy : 0.7785099744796753\n",
      "Train Loss     : -0.7749341318567593\n",
      "\n",
      "Test Accuracy  : 0.8006399869918823\n",
      "Test Loss      : -0.8015199557280008\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 22] Invalid argument: '../callbacks/<built-in function time>/logs/history.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36m<cell line: 144>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    140\u001b[0m         f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(total_time \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m60\u001b[39m)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m minutes\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_accuracies\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_accuracies, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m\"\u001b[39m: train_losses, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_accuracies\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_accuracies, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_losses\u001b[39m\u001b[38;5;124m\"\u001b[39m: test_losses}\n\u001b[1;32m--> 144\u001b[0m summary \u001b[38;5;241m=\u001b[39m \u001b[43mloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[1;32mIn [8]\u001b[0m, in \u001b[0;36mloop\u001b[1;34m(train, validate, epochs)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy  : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(test_accuracies) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_accuracies)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Loss      : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(test_losses) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_losses)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m../callbacks/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/logs/history.txt\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ma\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m    128\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSUMMARY:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    129\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Accuracy : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msum\u001b[39m(train_accuracies) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_accuracies)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: '../callbacks/<built-in function time>/logs/history.txt'"
     ]
    }
   ],
   "source": [
    "def train(dataloader, model, loss_metric, eval_metric, optimizer, time):\n",
    "    with open(\"../callbacks/\" + str(time) + \"/logs/history.txt\", \"a\") as f:\n",
    "        f.write(\"Train\\n\")\n",
    "        \n",
    "    print(\"Train\\n\")\n",
    "    \n",
    "    losses = []\n",
    "    \n",
    "    for batch, (feature, actual_label) in enumerate(dataloader, 1):\n",
    "        # Forward Propagation\n",
    "        pred_label = model(feature)\n",
    "        loss = loss_metric(pred_label, actual_label)\n",
    "        evaluate_metric = eval_metric(pred_label, actual_label)\n",
    "        \n",
    "        # Backward Propagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        loss = loss.item()\n",
    "        losses.append(loss)\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Batch-{batch:<4} | F1-Score: {evaluate_metric:>7f} | Loss: {loss:>7f}\")\n",
    "        \n",
    "            with open(\"../callbacks/\" + str(time) + \"/logs/history.txt\", \"a\") as f:\n",
    "                f.write(f\"Batch-{batch:<4} | F1-Score: {evaluate_metric:>7f} | Loss: {loss:>7f}\\n\")\n",
    "            \n",
    "    evaluate_metric = eval_metric.compute()\n",
    "    loss = sum(losses) / len(dataloader)\n",
    "    print(f\"Accuracy : {evaluate_metric}\")\n",
    "    print(f\"Loss     : {loss}\\n\")\n",
    "    \n",
    "    with open(\"../callbacks/\" + str(time) + \"/logs/history.txt\", \"a\") as f:\n",
    "        f.write(f\"Accuracy : {evaluate_metric}\\n\")\n",
    "        f.write(f\"Loss     : {loss}\\n\\n\")\n",
    "        \n",
    "    eval_metric.reset()\n",
    "    \n",
    "    return evaluate_metric, loss\n",
    "\n",
    "def validate(dataloader, model, loss_metric, eval_metric, time):\n",
    "    with open(\"../callbacks/\" + str(time) + \"/logs/history.txt\", \"a\") as f:\n",
    "        f.write(\"Test\\n\")\n",
    "        \n",
    "    print(\"Test\\n\")\n",
    "    \n",
    "    model.train()\n",
    "    losses = []\n",
    "    \n",
    "    for batch, (feature, actual_label) in enumerate(dataloader, 1):\n",
    "        # Forward Propagation\n",
    "        pred_label = model(feature)\n",
    "        loss = loss_metric(pred_label, actual_label)\n",
    "        evaluate_metric = eval_metric(pred_label, actual_label)\n",
    "        \n",
    "        \n",
    "        loss = loss.item()\n",
    "        losses.append(loss)\n",
    "        \n",
    "        if batch % 100 == 0:\n",
    "            print(f\"Batch-{batch:<4} | F1-Score: {evaluate_metric:>7f} | Loss: {loss:>7f}\")\n",
    "        \n",
    "            with open(\"../callbacks/\" + str(time) + \"/logs/history.txt\", \"a\") as f:\n",
    "                f.write(f\"Batch-{batch:<4} | F1-Score: {evaluate_metric:>7f} | Loss: {loss:>7f}\\n\")\n",
    "            \n",
    "    evaluate_metric = eval_metric.compute()\n",
    "    loss = sum(losses) / len(dataloader)\n",
    "    print(f\"Accuracy : {evaluate_metric}\")\n",
    "    print(f\"Loss     : {loss}\")\n",
    "    \n",
    "    with open(\"../callbacks/\" + str(time) + \"/logs/history.txt\", \"a\") as f:\n",
    "        f.write(f\"Accuracy : {evaluate_metric}\\n\")\n",
    "        f.write(f\"Loss     : {loss}\\n\\n\")\n",
    "        \n",
    "    eval_metric.reset()\n",
    "    \n",
    "    return evaluate_metric, loss\n",
    "\n",
    "def loop(train, validate, epochs=5):\n",
    "    now = datetime.now()\n",
    "    now = now.strftime(\"%m-%d-%Y_%H-%M-%S\")\n",
    "    os.makedirs(\"../callbacks/\" + str(now) + \"/models\")\n",
    "    os.makedirs(\"../callbacks/\" + str(now) + \"/logs\")\n",
    "\n",
    "    train_accuracies, train_losses = [], []\n",
    "    test_accuracies, test_losses = [], []\n",
    "\n",
    "    start = time()\n",
    "    for epoch in range(epochs):\n",
    "        with open(\"../callbacks/\" + str(now) + \"/logs/history.txt\", \"a\") as f:\n",
    "            f.write(f\"EPOCH {epoch + 1}/{epochs}\\n\")\n",
    "            f.write(f\"{'=' * 46}\\n\")\n",
    "            \n",
    "        print(f\"EPOCH {epoch + 1}/{epochs}\")\n",
    "        print(\"=\" * 46, end=\"\\n\")\n",
    "        acc_train, loss_train = train(train_loader, model, loss_metric, eval_metric, optimizer, now)\n",
    "        acc_test, loss_test = validate(test_loader, model, loss_metric, eval_metric, now)\n",
    "            \n",
    "        print(\"=\" * 46, end=\"\\n\\n\")\n",
    "        \n",
    "        with open(\"../callbacks/\" + str(now) + \"/logs/history.txt\", \"a\") as f:\n",
    "            f.write(f\"{'=' * 46}\\n\\n\")\n",
    "            \n",
    "        train_accuracies.append(acc_train)\n",
    "        train_losses.append(loss_train)\n",
    "        test_accuracies.append(acc_test)\n",
    "        test_losses.append(loss_test)\n",
    "        \n",
    "        torch.save(model.state_dict(), \"../callbacks/\" + now + \"/models/epoch_\" + str(epoch + 1) + \".pt\")\n",
    "    \n",
    "    metrics = {\n",
    "        \"train_accuracies\": train_accuracies,\n",
    "        \"train_losses\": train_losses,\n",
    "        \"test_accuracies\": test_accuracies,\n",
    "        \"test_losses\": test_losses\n",
    "    }\n",
    "    \n",
    "    torch.save(metrics, \"../callbacks/\" + now + \"/logs/metrics.pt\")\n",
    "\n",
    "    print(\"SUMMARY:\")\n",
    "    print(f\"Train Accuracy : {sum(train_accuracies) / len(train_accuracies)}\")\n",
    "    print(f\"Train Loss     : {sum(train_losses) / len(train_losses)}\\n\")\n",
    "    print(f\"Test Accuracy  : {sum(test_accuracies) / len(test_accuracies)}\")\n",
    "    print(f\"Test Loss      : {sum(test_losses) / len(test_losses)}\")\n",
    "    \n",
    "    with open(\"../callbacks/\" + now + \"/logs/history.txt\", \"a\") as f:\n",
    "        f.write(\"SUMMARY:\\n\")\n",
    "        f.write(f\"Train Accuracy : {sum(train_accuracies) / len(train_accuracies)}\\n\")\n",
    "        f.write(f\"Train Loss     : {sum(train_losses) / len(train_losses)}\\n\\n\")\n",
    "        f.write(f\"Test Accuracy  : {sum(test_accuracies) / len(test_accuracies)}\\n\")\n",
    "        f.write(f\"Test Loss      : {sum(test_losses) / len(test_losses)}\\n\")\n",
    "\n",
    "    stop = time()\n",
    "\n",
    "    total_time = stop - start\n",
    "    print(f\"Training time: {(total_time / 60):.3f} minutes\")\n",
    "    \n",
    "    with open(\"../callbacks/\" + now + \"/logs/history.txt\", \"a\") as f:\n",
    "        f.write(f\"Training time: {(total_time / 60):.3f} minutes\")\n",
    "        \n",
    "    return {\"train_accuracies\": train_accuracies, \"train_losses\": train_losses, \"test_accuracies\": test_accuracies, \"test_losses\": test_losses}\n",
    "\n",
    "summary = loop(train, validate, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e457dbe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T13:18:51.762698Z",
     "start_time": "2022-05-22T13:18:51.762698Z"
    }
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, tight_layout=True, figsize=(12, 8))\n",
    "\n",
    "ax[0][0].set_title(\"Train\")\n",
    "ax[0][0].plot(summary[\"train_accuracies\"], label=\"accuracy\")\n",
    "ax[0][0].plot(summary[\"train_losses\"], label=\"loss\")\n",
    "ax[0][0].set_xlabel(\"Epoch\")\n",
    "ax[0][0].set_ylabel(\"Score\")\n",
    "ax[0][0].legend()\n",
    "ax[0][0].grid();\n",
    "\n",
    "ax[0][1].set_title(\"Test\")\n",
    "ax[0][1].plot(summary[\"test_accuracies\"], label=\"accuracy\")\n",
    "ax[0][1].plot(summary[\"test_losses\"], label=\"loss\")\n",
    "ax[0][1].set_xlabel(\"Epoch\")\n",
    "ax[0][1].set_ylabel(\"Score\")\n",
    "ax[0][1].legend()\n",
    "ax[0][1].grid();\n",
    "\n",
    "ax[1][0].set_title(\"Train Accuracy and Test Accuracy\")\n",
    "ax[1][0].plot(summary[\"train_accuracies\"], label=\"accuracy train\")\n",
    "ax[1][0].plot(summary[\"test_accuracies\"], label=\"accuracy test\")\n",
    "ax[1][0].set_xlabel(\"Epoch\")\n",
    "ax[1][0].set_ylabel(\"Score\")\n",
    "ax[1][0].legend()\n",
    "ax[1][0].grid();\n",
    "\n",
    "ax[1][1].set_title(\"Train Loss and Test Loss\")\n",
    "ax[1][1].plot(summary[\"train_losses\"], label=\"loss train\")\n",
    "ax[1][1].plot(summary[\"test_losses\"], label=\"loss test\")\n",
    "ax[1][1].set_xlabel(\"Epoch\")\n",
    "ax[1][1].set_ylabel(\"Score\")\n",
    "ax[1][1].legend()\n",
    "ax[1][1].grid();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3fda32",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dfb650",
   "metadata": {},
   "source": [
    "## Predict with test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35779414",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T13:18:51.772465Z",
     "start_time": "2022-05-22T13:18:51.772465Z"
    }
   },
   "outputs": [],
   "source": [
    "features, labels = next(iter(test_loader))\n",
    "\n",
    "model.eval()\n",
    "pred_labels = model(features).argmax(dim=1)\n",
    "\n",
    "fig, axes = plt.subplots(8, 4, figsize=(24, 24))\n",
    "\n",
    "for image, label, pred_label, ax in zip(features, labels, pred_labels, axes.flatten()):\n",
    "    ax.imshow(image.permute(1, 2, 0).cpu(), cmap=plt.cm.gray)\n",
    "    font = {\"color\": \"red\"} if label != pred_label else {\"color\": \"green\"}\n",
    "    ax.set_title(f\"Label: {label} | Pred: {pred_label}\", fontdict=font)\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180379e7",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e8808c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T13:18:51.782350Z",
     "start_time": "2022-05-22T13:18:51.782350Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(model, dataloader):\n",
    "    actual_labels = dataloader.dataset.targets\n",
    "    features = dataloader.dataset.data.to(dtype=torch.float32)\n",
    "    \n",
    "    model.eval()\n",
    "    pred_labels = model(features).argmax(dim=1)\n",
    "    confusion_matrix = ConfusionMatrix(num_classes=10)\n",
    "    \n",
    "    ax = sns.heatmap(confusion_matrix(pred_labels, actual_labels), annot=True, fmt=\"d\")\n",
    "    ax.set(\n",
    "        xlabel=\"Prediction\",\n",
    "        ylabel=\"Actual\"\n",
    "    );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98543661",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T13:18:51.782350Z",
     "start_time": "2022-05-22T13:18:51.782350Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e282351",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-22T13:18:51.793698Z",
     "start_time": "2022-05-22T13:18:51.793698Z"
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851ed5a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:deep_learning] *",
   "language": "python",
   "name": "conda-env-deep_learning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "252.533px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
