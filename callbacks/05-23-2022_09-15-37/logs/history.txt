EPOCH 1/10
==============================================
Train
Batch-100  | F1-Score: 0.218750 | Loss: -0.241670
Batch-200  | F1-Score: 0.406250 | Loss: -0.424069
Batch-300  | F1-Score: 0.625000 | Loss: -0.620489
Batch-400  | F1-Score: 0.687500 | Loss: -0.650974
Batch-500  | F1-Score: 0.562500 | Loss: -0.588815
Batch-600  | F1-Score: 0.406250 | Loss: -0.432425
Batch-700  | F1-Score: 0.718750 | Loss: -0.710506
Batch-800  | F1-Score: 0.656250 | Loss: -0.662267
Batch-900  | F1-Score: 0.562500 | Loss: -0.579033
Batch-1000 | F1-Score: 0.687500 | Loss: -0.688672
Batch-1100 | F1-Score: 0.812500 | Loss: -0.791919
Batch-1200 | F1-Score: 0.750000 | Loss: -0.761838
Batch-1300 | F1-Score: 0.656250 | Loss: -0.670513
Batch-1400 | F1-Score: 0.687500 | Loss: -0.690274
Batch-1500 | F1-Score: 0.656250 | Loss: -0.665102
Batch-1600 | F1-Score: 0.625000 | Loss: -0.617762
Batch-1700 | F1-Score: 0.625000 | Loss: -0.633954
Batch-1800 | F1-Score: 0.625000 | Loss: -0.643886
Accuracy : 0.620983362197876
Loss     : -0.6212601509451866

Test
Batch-100  | F1-Score: 0.843750 | Loss: -0.820413
Batch-200  | F1-Score: 0.593750 | Loss: -0.620270
Batch-300  | F1-Score: 0.562500 | Loss: -0.552036
Accuracy : 0.6678000092506409
Loss     : -0.6809175975216083

==============================================

EPOCH 2/10
==============================================
Train
Batch-100  | F1-Score: 0.656250 | Loss: -0.670256
Batch-200  | F1-Score: 0.750000 | Loss: -0.751197
Batch-300  | F1-Score: 0.718750 | Loss: -0.715893
Batch-400  | F1-Score: 0.625000 | Loss: -0.647782
Batch-500  | F1-Score: 0.687500 | Loss: -0.696254
Batch-600  | F1-Score: 0.718750 | Loss: -0.739679
Batch-700  | F1-Score: 0.656250 | Loss: -0.657742
Batch-800  | F1-Score: 0.718750 | Loss: -0.739428
Batch-900  | F1-Score: 0.593750 | Loss: -0.613436
Batch-1000 | F1-Score: 0.625000 | Loss: -0.614553
Batch-1100 | F1-Score: 0.625000 | Loss: -0.643813
Batch-1200 | F1-Score: 0.656250 | Loss: -0.673587
Batch-1300 | F1-Score: 0.812500 | Loss: -0.801888
Batch-1400 | F1-Score: 0.750000 | Loss: -0.758667
Batch-1500 | F1-Score: 0.468750 | Loss: -0.495797
Batch-1600 | F1-Score: 0.625000 | Loss: -0.623484
Batch-1700 | F1-Score: 0.812500 | Loss: -0.820363
Batch-1800 | F1-Score: 0.781250 | Loss: -0.795717
Accuracy : 0.6681166887283325
Loss     : -0.6822866621017456

Test
Batch-100  | F1-Score: 0.656250 | Loss: -0.672634
Batch-200  | F1-Score: 0.718750 | Loss: -0.737691
Batch-300  | F1-Score: 0.781250 | Loss: -0.787577
Accuracy : 0.6721000075340271
Loss     : -0.6892102180768888

==============================================

EPOCH 3/10
==============================================
Train
Batch-100  | F1-Score: 0.812500 | Loss: -0.815086
Batch-200  | F1-Score: 0.718750 | Loss: -0.733307
Batch-300  | F1-Score: 0.687500 | Loss: -0.711249
Batch-400  | F1-Score: 0.687500 | Loss: -0.697519
Batch-500  | F1-Score: 0.781250 | Loss: -0.774528
Batch-600  | F1-Score: 0.500000 | Loss: -0.507052
Batch-700  | F1-Score: 0.437500 | Loss: -0.479182
Batch-800  | F1-Score: 0.562500 | Loss: -0.600402
Batch-900  | F1-Score: 0.593750 | Loss: -0.623032
Batch-1000 | F1-Score: 0.718750 | Loss: -0.737710
Batch-1100 | F1-Score: 0.718750 | Loss: -0.736563
Batch-1200 | F1-Score: 0.687500 | Loss: -0.691649
Batch-1300 | F1-Score: 0.593750 | Loss: -0.623149
Batch-1400 | F1-Score: 0.562500 | Loss: -0.590601
Batch-1500 | F1-Score: 0.625000 | Loss: -0.650580
Batch-1600 | F1-Score: 0.750000 | Loss: -0.768964
Batch-1700 | F1-Score: 0.531250 | Loss: -0.555468
Batch-1800 | F1-Score: 0.718750 | Loss: -0.730045
Accuracy : 0.6734499931335449
Loss     : -0.691048092619578

Test
Batch-100  | F1-Score: 0.781250 | Loss: -0.771837
Batch-200  | F1-Score: 0.687500 | Loss: -0.701253
Batch-300  | F1-Score: 0.625000 | Loss: -0.642001
Accuracy : 0.6769000291824341
Loss     : -0.6952472456727927

==============================================

EPOCH 4/10
==============================================
Train
Batch-100  | F1-Score: 0.718750 | Loss: -0.735927
Batch-200  | F1-Score: 0.656250 | Loss: -0.688396
Batch-300  | F1-Score: 0.718750 | Loss: -0.740975
Batch-400  | F1-Score: 0.656250 | Loss: -0.682897
Batch-500  | F1-Score: 0.562500 | Loss: -0.598992
Batch-600  | F1-Score: 0.718750 | Loss: -0.739826
Batch-700  | F1-Score: 0.687500 | Loss: -0.703602
Batch-800  | F1-Score: 0.593750 | Loss: -0.619269
Batch-900  | F1-Score: 0.625000 | Loss: -0.656208
Batch-1000 | F1-Score: 0.625000 | Loss: -0.642546
Batch-1100 | F1-Score: 0.656250 | Loss: -0.674156
Batch-1200 | F1-Score: 0.781250 | Loss: -0.786052
Batch-1300 | F1-Score: 0.687500 | Loss: -0.708945
Batch-1400 | F1-Score: 0.750000 | Loss: -0.768023
Batch-1500 | F1-Score: 0.750000 | Loss: -0.766353
Batch-1600 | F1-Score: 0.718750 | Loss: -0.725272
Batch-1700 | F1-Score: 0.656250 | Loss: -0.688785
Batch-1800 | F1-Score: 0.812500 | Loss: -0.825029
Accuracy : 0.6772000193595886
Loss     : -0.6963953446547191

Test
Batch-100  | F1-Score: 0.625000 | Loss: -0.664059
Batch-200  | F1-Score: 0.750000 | Loss: -0.765725
Batch-300  | F1-Score: 0.812500 | Loss: -0.818573
Accuracy : 0.6776000261306763
Loss     : -0.6975006760118868

==============================================

EPOCH 5/10
==============================================
Train
Batch-100  | F1-Score: 0.625000 | Loss: -0.637215
Batch-200  | F1-Score: 0.750000 | Loss: -0.767286
Batch-300  | F1-Score: 0.593750 | Loss: -0.616261
Batch-400  | F1-Score: 0.812500 | Loss: -0.821206
Batch-500  | F1-Score: 0.781250 | Loss: -0.798600
Batch-600  | F1-Score: 0.718750 | Loss: -0.711171
Batch-700  | F1-Score: 0.843750 | Loss: -0.839786
Batch-800  | F1-Score: 0.656250 | Loss: -0.671862
Batch-900  | F1-Score: 0.656250 | Loss: -0.685009
Batch-1000 | F1-Score: 0.562500 | Loss: -0.590598
Batch-1100 | F1-Score: 0.781250 | Loss: -0.787579
Batch-1200 | F1-Score: 0.718750 | Loss: -0.743941
Batch-1300 | F1-Score: 0.562500 | Loss: -0.591914
Batch-1400 | F1-Score: 0.718750 | Loss: -0.739480
Batch-1500 | F1-Score: 0.843750 | Loss: -0.851480
Batch-1600 | F1-Score: 0.781250 | Loss: -0.801943
Batch-1700 | F1-Score: 0.718750 | Loss: -0.740400
Batch-1800 | F1-Score: 0.625000 | Loss: -0.654789
Accuracy : 0.6794666647911072
Loss     : -0.6999348225116729

Test
Batch-100  | F1-Score: 0.750000 | Loss: -0.767033
Batch-200  | F1-Score: 0.687500 | Loss: -0.711164
Batch-300  | F1-Score: 0.750000 | Loss: -0.760895
Accuracy : 0.6804999709129333
Loss     : -0.7010902108285374

==============================================

EPOCH 6/10
==============================================
Train
Batch-100  | F1-Score: 0.593750 | Loss: -0.623214
Batch-200  | F1-Score: 0.531250 | Loss: -0.552841
Batch-300  | F1-Score: 0.687500 | Loss: -0.711370
Batch-400  | F1-Score: 0.656250 | Loss: -0.685007
Batch-500  | F1-Score: 0.687500 | Loss: -0.714152
Batch-600  | F1-Score: 0.625000 | Loss: -0.654216
Batch-700  | F1-Score: 0.593750 | Loss: -0.624265
Batch-800  | F1-Score: 0.812500 | Loss: -0.825789
Batch-900  | F1-Score: 0.718750 | Loss: -0.743698
Batch-1000 | F1-Score: 0.625000 | Loss: -0.659191
Batch-1100 | F1-Score: 0.750000 | Loss: -0.761485
Batch-1200 | F1-Score: 0.468750 | Loss: -0.494008
Batch-1300 | F1-Score: 0.750000 | Loss: -0.774368
Batch-1400 | F1-Score: 0.531250 | Loss: -0.570336
Batch-1500 | F1-Score: 0.781250 | Loss: -0.792974
Batch-1600 | F1-Score: 0.687500 | Loss: -0.696072
Batch-1700 | F1-Score: 0.968750 | Loss: -0.967304
Batch-1800 | F1-Score: 0.656250 | Loss: -0.683037
Accuracy : 0.6803833246231079
Loss     : -0.7018949943065643

Test
Batch-100  | F1-Score: 0.593750 | Loss: -0.625935
Batch-200  | F1-Score: 0.687500 | Loss: -0.706495
Batch-300  | F1-Score: 0.781250 | Loss: -0.798706
Accuracy : 0.679099977016449
Loss     : -0.7012507960247917

==============================================

EPOCH 7/10
==============================================
Train
Batch-100  | F1-Score: 0.531250 | Loss: -0.568774
Batch-200  | F1-Score: 0.812500 | Loss: -0.830844
Batch-300  | F1-Score: 0.781250 | Loss: -0.783071
Batch-400  | F1-Score: 0.593750 | Loss: -0.630802
Batch-500  | F1-Score: 0.562500 | Loss: -0.594978
Batch-600  | F1-Score: 0.718750 | Loss: -0.740670
Batch-700  | F1-Score: 0.593750 | Loss: -0.604344
Batch-800  | F1-Score: 0.781250 | Loss: -0.782873
Batch-900  | F1-Score: 0.718750 | Loss: -0.741085
Batch-1000 | F1-Score: 0.625000 | Loss: -0.647383
Batch-1100 | F1-Score: 0.718750 | Loss: -0.737762
Batch-1200 | F1-Score: 0.687500 | Loss: -0.683728
Batch-1300 | F1-Score: 0.718750 | Loss: -0.737676
Batch-1400 | F1-Score: 0.843750 | Loss: -0.855301
Batch-1500 | F1-Score: 0.718750 | Loss: -0.747240
Batch-1600 | F1-Score: 0.812500 | Loss: -0.826186
Batch-1700 | F1-Score: 0.750000 | Loss: -0.772352
Batch-1800 | F1-Score: 0.687500 | Loss: -0.702968
Accuracy : 0.682533323764801
Loss     : -0.7045348333358765

Test
Batch-100  | F1-Score: 0.750000 | Loss: -0.765264
Batch-200  | F1-Score: 0.718750 | Loss: -0.736592
Batch-300  | F1-Score: 0.625000 | Loss: -0.621136
Accuracy : 0.6794999837875366
Loss     : -0.7028205156707155

==============================================

EPOCH 8/10
==============================================
Train
Batch-100  | F1-Score: 0.593750 | Loss: -0.603632
Batch-200  | F1-Score: 0.718750 | Loss: -0.742148
Batch-300  | F1-Score: 0.593750 | Loss: -0.618967
Batch-400  | F1-Score: 0.750000 | Loss: -0.752504
Batch-500  | F1-Score: 0.687500 | Loss: -0.714339
Batch-600  | F1-Score: 0.656250 | Loss: -0.675803
Batch-700  | F1-Score: 0.656250 | Loss: -0.676922
Batch-800  | F1-Score: 0.750000 | Loss: -0.768017
Batch-900  | F1-Score: 0.843750 | Loss: -0.857445
Batch-1000 | F1-Score: 0.625000 | Loss: -0.653106
Batch-1100 | F1-Score: 0.781250 | Loss: -0.802036
Batch-1200 | F1-Score: 0.625000 | Loss: -0.643061
Batch-1300 | F1-Score: 0.625000 | Loss: -0.635214
Batch-1400 | F1-Score: 0.750000 | Loss: -0.770954
Batch-1500 | F1-Score: 0.843750 | Loss: -0.851448
Batch-1600 | F1-Score: 0.718750 | Loss: -0.738747
Batch-1700 | F1-Score: 0.656250 | Loss: -0.680570
Batch-1800 | F1-Score: 0.687500 | Loss: -0.712737
Accuracy : 0.6838333606719971
Loss     : -0.7059286407470703

Test
Batch-100  | F1-Score: 0.750000 | Loss: -0.759618
Batch-200  | F1-Score: 0.687500 | Loss: -0.714445
Batch-300  | F1-Score: 0.625000 | Loss: -0.657337
Accuracy : 0.6822999715805054
Loss     : -0.7047690874852311

==============================================

EPOCH 9/10
==============================================
Train
Batch-100  | F1-Score: 0.625000 | Loss: -0.653901
Batch-200  | F1-Score: 0.625000 | Loss: -0.657107
Batch-300  | F1-Score: 0.656250 | Loss: -0.687129
Batch-400  | F1-Score: 0.781250 | Loss: -0.800987
Batch-500  | F1-Score: 0.625000 | Loss: -0.652460
Batch-600  | F1-Score: 0.687500 | Loss: -0.708618
Batch-700  | F1-Score: 0.718750 | Loss: -0.754291
Batch-800  | F1-Score: 0.625000 | Loss: -0.642187
Batch-900  | F1-Score: 0.750000 | Loss: -0.768338
Batch-1000 | F1-Score: 0.625000 | Loss: -0.656120
Batch-1100 | F1-Score: 0.781250 | Loss: -0.783298
Batch-1200 | F1-Score: 0.687500 | Loss: -0.708873
Batch-1300 | F1-Score: 0.625000 | Loss: -0.652617
Batch-1400 | F1-Score: 0.718750 | Loss: -0.734334
Batch-1500 | F1-Score: 0.625000 | Loss: -0.661472
Batch-1600 | F1-Score: 0.750000 | Loss: -0.773467
Batch-1700 | F1-Score: 0.656250 | Loss: -0.685672
Batch-1800 | F1-Score: 0.812500 | Loss: -0.819593
Accuracy : 0.6842666864395142
Loss     : -0.7071514774004618

Test
Batch-100  | F1-Score: 0.781250 | Loss: -0.769824
Batch-200  | F1-Score: 0.656250 | Loss: -0.670596
Batch-300  | F1-Score: 0.718750 | Loss: -0.736917
Accuracy : 0.6822999715805054
Loss     : -0.7044763324169305

==============================================

EPOCH 10/10
==============================================
Train
Batch-100  | F1-Score: 0.812500 | Loss: -0.828117
Batch-200  | F1-Score: 0.718750 | Loss: -0.731064
Batch-300  | F1-Score: 0.718750 | Loss: -0.746523
Batch-400  | F1-Score: 0.625000 | Loss: -0.649672
Batch-500  | F1-Score: 0.656250 | Loss: -0.681651
Batch-600  | F1-Score: 0.593750 | Loss: -0.620310
Batch-700  | F1-Score: 0.562500 | Loss: -0.592409
Batch-800  | F1-Score: 0.500000 | Loss: -0.542472
Batch-900  | F1-Score: 0.843750 | Loss: -0.859365
Batch-1000 | F1-Score: 0.750000 | Loss: -0.770470
Batch-1100 | F1-Score: 0.593750 | Loss: -0.628082
Batch-1200 | F1-Score: 0.625000 | Loss: -0.654201
Batch-1300 | F1-Score: 0.687500 | Loss: -0.712169
Batch-1400 | F1-Score: 0.625000 | Loss: -0.654969
Batch-1500 | F1-Score: 0.531250 | Loss: -0.563808
Batch-1600 | F1-Score: 0.656250 | Loss: -0.687951
Batch-1700 | F1-Score: 0.625000 | Loss: -0.655605
Batch-1800 | F1-Score: 0.687500 | Loss: -0.711495
Accuracy : 0.6854000091552734
Loss     : -0.7083082010587056

Test
Batch-100  | F1-Score: 0.875000 | Loss: -0.858321
Batch-200  | F1-Score: 0.593750 | Loss: -0.609686
Batch-300  | F1-Score: 0.562500 | Loss: -0.600493
Accuracy : 0.6815000176429749
Loss     : -0.7047017884140198

==============================================

SUMMARY:
Train Accuracy : 0.6735633611679077
Train Loss     : -0.6918743219681581

Test Accuracy  : 0.6779600381851196
Test Loss      : -0.6981984468123401
Training time: 3.038 minutes