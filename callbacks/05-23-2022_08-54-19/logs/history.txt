EPOCH 1/10
==============================================
Train
Batch-100  | F1-Score: 0.812500 | Loss: -0.610907
Batch-200  | F1-Score: 0.718750 | Loss: -0.684039
Batch-300  | F1-Score: 0.687500 | Loss: -0.670261
Batch-400  | F1-Score: 0.781250 | Loss: -0.759460
Batch-500  | F1-Score: 0.750000 | Loss: -0.695019
Batch-600  | F1-Score: 0.937500 | Loss: -0.925963
Batch-700  | F1-Score: 0.750000 | Loss: -0.758255
Batch-800  | F1-Score: 0.562500 | Loss: -0.574173
Batch-900  | F1-Score: 0.781250 | Loss: -0.779133
Batch-1000 | F1-Score: 0.718750 | Loss: -0.717040
Batch-1100 | F1-Score: 0.750000 | Loss: -0.751888
Batch-1200 | F1-Score: 0.812500 | Loss: -0.788163
Batch-1300 | F1-Score: 0.875000 | Loss: -0.846291
Batch-1400 | F1-Score: 0.812500 | Loss: -0.818371
Batch-1500 | F1-Score: 0.875000 | Loss: -0.866515
Batch-1600 | F1-Score: 0.781250 | Loss: -0.776709
Batch-1700 | F1-Score: 0.781250 | Loss: -0.743647
Batch-1800 | F1-Score: 0.843750 | Loss: -0.811725
Accuracy : 0.7570000886917114
Loss     : -0.7345023154457411

Test
Batch-100  | F1-Score: 0.875000 | Loss: -0.869285
Batch-200  | F1-Score: 0.906250 | Loss: -0.874327
Batch-300  | F1-Score: 0.843750 | Loss: -0.829058
Accuracy : 0.8345999717712402
Loss     : -0.8249395544917438

==============================================

EPOCH 2/10
==============================================
Train
Batch-100  | F1-Score: 0.750000 | Loss: -0.747268
Batch-200  | F1-Score: 0.750000 | Loss: -0.756497
Batch-300  | F1-Score: 0.781250 | Loss: -0.780637
Batch-400  | F1-Score: 0.875000 | Loss: -0.870832
Batch-500  | F1-Score: 0.875000 | Loss: -0.866384
Batch-600  | F1-Score: 0.875000 | Loss: -0.864410
Batch-700  | F1-Score: 0.843750 | Loss: -0.826562
Batch-800  | F1-Score: 0.781250 | Loss: -0.786981
Batch-900  | F1-Score: 0.843750 | Loss: -0.814103
Batch-1000 | F1-Score: 0.812500 | Loss: -0.822103
Batch-1100 | F1-Score: 0.937500 | Loss: -0.928594
Batch-1200 | F1-Score: 0.781250 | Loss: -0.779142
Batch-1300 | F1-Score: 0.906250 | Loss: -0.900863
Batch-1400 | F1-Score: 0.687500 | Loss: -0.694767
Batch-1500 | F1-Score: 0.750000 | Loss: -0.748977
Batch-1600 | F1-Score: 0.843750 | Loss: -0.834200
Batch-1700 | F1-Score: 0.875000 | Loss: -0.864666
Batch-1800 | F1-Score: 0.781250 | Loss: -0.770607
Accuracy : 0.8410000205039978
Loss     : -0.8336547398885091

Test
Batch-100  | F1-Score: 0.875000 | Loss: -0.882079
Batch-200  | F1-Score: 0.812500 | Loss: -0.834936
Batch-300  | F1-Score: 0.750000 | Loss: -0.750619
Accuracy : 0.8471999764442444
Loss     : -0.8414719822688606

==============================================

EPOCH 3/10
==============================================
Train
Batch-100  | F1-Score: 0.906250 | Loss: -0.899098
Batch-200  | F1-Score: 0.906250 | Loss: -0.904685
Batch-300  | F1-Score: 0.843750 | Loss: -0.841665
Batch-400  | F1-Score: 0.937500 | Loss: -0.928393
Batch-500  | F1-Score: 0.781250 | Loss: -0.776118
Batch-600  | F1-Score: 0.781250 | Loss: -0.759115
Batch-700  | F1-Score: 0.906250 | Loss: -0.904113
Batch-800  | F1-Score: 0.843750 | Loss: -0.852986
Batch-900  | F1-Score: 0.812500 | Loss: -0.815695
Batch-1000 | F1-Score: 0.812500 | Loss: -0.810141
Batch-1100 | F1-Score: 0.843750 | Loss: -0.829243
Batch-1200 | F1-Score: 0.906250 | Loss: -0.902765
Batch-1300 | F1-Score: 0.937500 | Loss: -0.947945
Batch-1400 | F1-Score: 0.906250 | Loss: -0.903544
Batch-1500 | F1-Score: 0.750000 | Loss: -0.757947
Batch-1600 | F1-Score: 0.906250 | Loss: -0.902428
Batch-1700 | F1-Score: 0.875000 | Loss: -0.864282
Batch-1800 | F1-Score: 0.968750 | Loss: -0.964734
Accuracy : 0.8523499965667725
Loss     : -0.8468848162968954

Test
Batch-100  | F1-Score: 0.812500 | Loss: -0.814952
Batch-200  | F1-Score: 0.843750 | Loss: -0.838564
Batch-300  | F1-Score: 0.875000 | Loss: -0.870852
Accuracy : 0.8539000153541565
Loss     : -0.8486916177189008

==============================================

EPOCH 4/10
==============================================
Train
Batch-100  | F1-Score: 0.781250 | Loss: -0.777090
Batch-200  | F1-Score: 0.750000 | Loss: -0.754248
Batch-300  | F1-Score: 0.906250 | Loss: -0.885100
Batch-400  | F1-Score: 0.843750 | Loss: -0.828841
Batch-500  | F1-Score: 0.875000 | Loss: -0.862647
Batch-600  | F1-Score: 0.843750 | Loss: -0.827229
Batch-700  | F1-Score: 0.875000 | Loss: -0.871558
Batch-800  | F1-Score: 0.843750 | Loss: -0.836186
Batch-900  | F1-Score: 0.968750 | Loss: -0.960420
Batch-1000 | F1-Score: 0.781250 | Loss: -0.788116
Batch-1100 | F1-Score: 0.906250 | Loss: -0.905991
Batch-1200 | F1-Score: 0.781250 | Loss: -0.781729
Batch-1300 | F1-Score: 0.968750 | Loss: -0.964933
Batch-1400 | F1-Score: 0.906250 | Loss: -0.900765
Batch-1500 | F1-Score: 0.875000 | Loss: -0.858335
Batch-1600 | F1-Score: 0.937500 | Loss: -0.929875
Batch-1700 | F1-Score: 0.968750 | Loss: -0.946737
Batch-1800 | F1-Score: 0.812500 | Loss: -0.810388
Accuracy : 0.8583666682243347
Loss     : -0.8540425886154175

Test
Batch-100  | F1-Score: 0.937500 | Loss: -0.938268
Batch-200  | F1-Score: 0.937500 | Loss: -0.905387
Batch-300  | F1-Score: 0.750000 | Loss: -0.743268
Accuracy : 0.8587999939918518
Loss     : -0.8554754089623594

==============================================

EPOCH 5/10
==============================================
Train
Batch-100  | F1-Score: 0.781250 | Loss: -0.780442
Batch-200  | F1-Score: 0.843750 | Loss: -0.850141
Batch-300  | F1-Score: 0.906250 | Loss: -0.906008
Batch-400  | F1-Score: 0.843750 | Loss: -0.842430
Batch-500  | F1-Score: 0.843750 | Loss: -0.827369
Batch-600  | F1-Score: 0.812500 | Loss: -0.796354
Batch-700  | F1-Score: 0.937500 | Loss: -0.942759
Batch-800  | F1-Score: 0.906250 | Loss: -0.908530
Batch-900  | F1-Score: 0.875000 | Loss: -0.874463
Batch-1000 | F1-Score: 0.906250 | Loss: -0.878029
Batch-1100 | F1-Score: 0.843750 | Loss: -0.852403
Batch-1200 | F1-Score: 0.875000 | Loss: -0.848263
Batch-1300 | F1-Score: 0.843750 | Loss: -0.844768
Batch-1400 | F1-Score: 0.937500 | Loss: -0.936791
Batch-1500 | F1-Score: 0.906250 | Loss: -0.904508
Batch-1600 | F1-Score: 0.906250 | Loss: -0.917262
Batch-1700 | F1-Score: 0.906250 | Loss: -0.903070
Batch-1800 | F1-Score: 0.937500 | Loss: -0.930596
Accuracy : 0.8624666929244995
Loss     : -0.8589189638137817

Test
Batch-100  | F1-Score: 0.781250 | Loss: -0.776849
Batch-200  | F1-Score: 0.843750 | Loss: -0.829615
Batch-300  | F1-Score: 0.906250 | Loss: -0.907775
Accuracy : 0.8622000217437744
Loss     : -0.8588254817377645

==============================================

EPOCH 6/10
==============================================
Train
Batch-100  | F1-Score: 0.906250 | Loss: -0.905559
Batch-200  | F1-Score: 0.875000 | Loss: -0.874176
Batch-300  | F1-Score: 0.906250 | Loss: -0.906024
Batch-400  | F1-Score: 0.906250 | Loss: -0.895748
Batch-500  | F1-Score: 0.875000 | Loss: -0.857508
Batch-600  | F1-Score: 0.812500 | Loss: -0.807923
Batch-700  | F1-Score: 0.875000 | Loss: -0.874675
Batch-800  | F1-Score: 0.812500 | Loss: -0.823300
Batch-900  | F1-Score: 0.781250 | Loss: -0.768465
Batch-1000 | F1-Score: 0.906250 | Loss: -0.902808
Batch-1100 | F1-Score: 0.750000 | Loss: -0.766296
Batch-1200 | F1-Score: 0.875000 | Loss: -0.881626
Batch-1300 | F1-Score: 0.906250 | Loss: -0.903094
Batch-1400 | F1-Score: 0.875000 | Loss: -0.867725
Batch-1500 | F1-Score: 0.812500 | Loss: -0.820838
Batch-1600 | F1-Score: 0.875000 | Loss: -0.874004
Batch-1700 | F1-Score: 0.937500 | Loss: -0.926499
Batch-1800 | F1-Score: 0.843750 | Loss: -0.837419
Accuracy : 0.8661999702453613
Loss     : -0.8628549006144206

Test
Batch-100  | F1-Score: 0.843750 | Loss: -0.833740
Batch-200  | F1-Score: 0.875000 | Loss: -0.879511
Batch-300  | F1-Score: 0.875000 | Loss: -0.864922
Accuracy : 0.8658000826835632
Loss     : -0.8623617706588282

==============================================

EPOCH 7/10
==============================================
Train
Batch-100  | F1-Score: 0.906250 | Loss: -0.905983
Batch-200  | F1-Score: 0.875000 | Loss: -0.874555
Batch-300  | F1-Score: 0.937500 | Loss: -0.935839
Batch-400  | F1-Score: 0.843750 | Loss: -0.838822
Batch-500  | F1-Score: 0.875000 | Loss: -0.873493
Batch-600  | F1-Score: 0.875000 | Loss: -0.870107
Batch-700  | F1-Score: 0.906250 | Loss: -0.899382
Batch-800  | F1-Score: 0.781250 | Loss: -0.795215
Batch-900  | F1-Score: 0.750000 | Loss: -0.739005
Batch-1000 | F1-Score: 0.812500 | Loss: -0.811058
Batch-1100 | F1-Score: 0.812500 | Loss: -0.808973
Batch-1200 | F1-Score: 0.812500 | Loss: -0.816064
Batch-1300 | F1-Score: 0.718750 | Loss: -0.718449
Batch-1400 | F1-Score: 0.906250 | Loss: -0.903555
Batch-1500 | F1-Score: 0.875000 | Loss: -0.862006
Batch-1600 | F1-Score: 0.843750 | Loss: -0.841934
Batch-1700 | F1-Score: 0.843750 | Loss: -0.844502
Batch-1800 | F1-Score: 0.875000 | Loss: -0.862347
Accuracy : 0.86885005235672
Loss     : -0.8659693724632264

Test
Batch-100  | F1-Score: 0.906250 | Loss: -0.911182
Batch-200  | F1-Score: 0.937500 | Loss: -0.936777
Batch-300  | F1-Score: 0.968750 | Loss: -0.960503
Accuracy : 0.8655999898910522
Loss     : -0.8623291606339403

==============================================

EPOCH 8/10
==============================================
Train
Batch-100  | F1-Score: 0.937500 | Loss: -0.925421
Batch-200  | F1-Score: 0.906250 | Loss: -0.905938
Batch-300  | F1-Score: 0.875000 | Loss: -0.863676
Batch-400  | F1-Score: 0.875000 | Loss: -0.874742
Batch-500  | F1-Score: 0.906250 | Loss: -0.904841
Batch-600  | F1-Score: 0.875000 | Loss: -0.871821
Batch-700  | F1-Score: 0.906250 | Loss: -0.906803
Batch-800  | F1-Score: 0.875000 | Loss: -0.871257
Batch-900  | F1-Score: 0.875000 | Loss: -0.868950
Batch-1000 | F1-Score: 0.843750 | Loss: -0.842840
Batch-1100 | F1-Score: 0.937500 | Loss: -0.913935
Batch-1200 | F1-Score: 0.843750 | Loss: -0.841350
Batch-1300 | F1-Score: 0.906250 | Loss: -0.919951
Batch-1400 | F1-Score: 0.875000 | Loss: -0.863648
Batch-1500 | F1-Score: 0.937500 | Loss: -0.938439
Batch-1600 | F1-Score: 0.906250 | Loss: -0.916406
Batch-1700 | F1-Score: 0.906250 | Loss: -0.902723
Batch-1800 | F1-Score: 0.812500 | Loss: -0.817262
Accuracy : 0.871399998664856
Loss     : -0.8684863099098206

Test
Batch-100  | F1-Score: 0.906250 | Loss: -0.916696
Batch-200  | F1-Score: 0.906250 | Loss: -0.905563
Batch-300  | F1-Score: 0.937500 | Loss: -0.936667
Accuracy : 0.8672000169754028
Loss     : -0.8654335838156386

==============================================

EPOCH 9/10
==============================================
Train
Batch-100  | F1-Score: 0.812500 | Loss: -0.807703
Batch-200  | F1-Score: 0.843750 | Loss: -0.849456
Batch-300  | F1-Score: 0.875000 | Loss: -0.873823
Batch-400  | F1-Score: 0.906250 | Loss: -0.906020
Batch-500  | F1-Score: 0.968750 | Loss: -0.968598
Batch-600  | F1-Score: 0.906250 | Loss: -0.906252
Batch-700  | F1-Score: 0.937500 | Loss: -0.931806
Batch-800  | F1-Score: 0.937500 | Loss: -0.937235
Batch-900  | F1-Score: 0.906250 | Loss: -0.919702
Batch-1000 | F1-Score: 0.875000 | Loss: -0.874167
Batch-1100 | F1-Score: 0.875000 | Loss: -0.869988
Batch-1200 | F1-Score: 0.906250 | Loss: -0.918377
Batch-1300 | F1-Score: 0.843750 | Loss: -0.843713
Batch-1400 | F1-Score: 0.875000 | Loss: -0.865792
Batch-1500 | F1-Score: 0.812500 | Loss: -0.812131
Batch-1600 | F1-Score: 0.906250 | Loss: -0.905383
Batch-1700 | F1-Score: 0.937500 | Loss: -0.903420
Batch-1800 | F1-Score: 0.906250 | Loss: -0.900546
Accuracy : 0.8733166456222534
Loss     : -0.870692474269867

Test
Batch-100  | F1-Score: 0.875000 | Loss: -0.874538
Batch-200  | F1-Score: 0.812500 | Loss: -0.823510
Batch-300  | F1-Score: 0.875000 | Loss: -0.878309
Accuracy : 0.8687999844551086
Loss     : -0.8659331360564064

==============================================

EPOCH 10/10
==============================================
Train
Batch-100  | F1-Score: 0.781250 | Loss: -0.765728
Batch-200  | F1-Score: 0.937500 | Loss: -0.935146
Batch-300  | F1-Score: 0.968750 | Loss: -0.961440
Batch-400  | F1-Score: 0.843750 | Loss: -0.842738
Batch-500  | F1-Score: 0.906250 | Loss: -0.898525
Batch-600  | F1-Score: 0.843750 | Loss: -0.849198
Batch-700  | F1-Score: 0.781250 | Loss: -0.770105
Batch-800  | F1-Score: 0.875000 | Loss: -0.874697
Batch-900  | F1-Score: 0.906250 | Loss: -0.904635
Batch-1000 | F1-Score: 0.937500 | Loss: -0.922795
Batch-1100 | F1-Score: 0.843750 | Loss: -0.843770
Batch-1200 | F1-Score: 0.906250 | Loss: -0.906163
Batch-1300 | F1-Score: 0.750000 | Loss: -0.750444
Batch-1400 | F1-Score: 0.906250 | Loss: -0.906107
Batch-1500 | F1-Score: 0.750000 | Loss: -0.741874
Batch-1600 | F1-Score: 0.875000 | Loss: -0.874514
Batch-1700 | F1-Score: 0.781250 | Loss: -0.780925
Batch-1800 | F1-Score: 0.906250 | Loss: -0.896500
Accuracy : 0.8743833303451538
Loss     : -0.872119669564565

Test
Batch-100  | F1-Score: 0.843750 | Loss: -0.843675
Batch-200  | F1-Score: 0.781250 | Loss: -0.779472
Batch-300  | F1-Score: 0.906250 | Loss: -0.906028
Accuracy : 0.8700000047683716
Loss     : -0.8675090600126467

==============================================

SUMMARY:
Train Accuracy : 0.8525333404541016
Train Loss     : -0.8468126150882244

Test Accuracy  : 0.8594099879264832
Test Loss      : -0.8552970756357089
Training time: 2.784 minutes